## Data 
For the sake of thisd task to simplify things a lot I have decided to work with movie title, genre and plot only. As a result I have only used `movies_metadata.csv` and decided to not to look after other data like director, actor etc. <br/> **This recommendation system has another shortcoming as it doesn't consider the language of the movie.** <br/> 
* I took only 4 columns `genre`, `title`, `overview` and `tagline` as they are the closest and easiest way to get the plot of the movie.   
* Once I filtered those columns I have cleaned `genre` column as it contatiting dictionaries with keys id and name. I extracted only name from these dictionaries and created a list out of it for every data points. Then I merged `overview` and `tagline` columns together to create `content` column which will act as out plot for the movie. 
* So now we have only `genre`, `title` and `content` columns. Now there are some duplicates in the `title`. I assumed that every movie having same `title` is actually the same movie and just described differently for promotional purpose. 
* So we have two kinds of measure basede on which we find similarities between movies. One is `genre` and the other is `content`. 
* I decided to use `TFIDF` for `content` and `count vectorizer` for `genre`. 
    + _TFIDF_ - TFIDF is the product of two terms- term frquency and inverse document frquency. Term frquency is the number of times a certain word is appering in the corpus. It is the raw frequency divided by the raw frequency of the most occurring term in the document. Inverse document frquency is the measure of how much information a certain word is carrying.  It is the logarithmically scaled inverse fraction of the documents that contain the word (obtained by dividing the total number of documents by the number of documents containing the term, and then taking the logarithm of that quotient).
    + _Count Vectorizer_ -  It counts the number of times a token shows up in the document and uses this value as its weight.
* The `content` can be thought of a full corpus containing description in detail, so as a result `TFIDF` will give better measure of the words in the vector space. 
* Whereas `genre` can be thought of keywords list for which `count` will give better respresentation of the vector space.
* Once these are prepared I calculated the cosine similiarity matrix for each movie tile based on the vector space respresentation of `genre` and `content` seperately. So, for I have two matrices, one containing cosine similarities of `genre` column and another based on `content` column.
    + _Cosine Similarity_ - Cosine similarity is a measure of similarity between two non-zero vectors of an inner product space that measures the cosine of the angle between them. The cosine of 0° is 1, and it is less than 1 for any angle in the interval (0,π] radians. It is thus a judgment of orientation and not magnitude: two vectors with the same orientation have a cosine similarity of 1, two vectors oriented at 90° relative to each other have a similarity of 0, and two vectors diametrically opposed have a similarity of -1, independent of their magnitude.
* After calculating and storing those cosine similarities I decide to give 50-50 weightage (arbritarity) to both `genre` and `content`. And sum them together to calculate similarity score btween differn movie `title`s. And sort the scores from high to low and return first `n` number of movies as recommendation 
